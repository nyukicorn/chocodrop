name: Worktree Parallel Testing
# AI-powered parallel branch comparison workflow

on:
  workflow_dispatch:
    inputs:
      branches:
        description: 'Comma-separated branch names to test (e.g., task/feature-a,task/feature-b,task/feature-c)'
        required: true
        type: string
      run_build:
        description: 'Run build for each branch'
        required: false
        type: boolean
        default: true
      run_tests:
        description: 'Run tests for each branch'
        required: false
        type: boolean
        default: true
      compare_results:
        description: 'Generate comparison report'
        required: false
        type: boolean
        default: true

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  prepare:
    name: Prepare branch matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      branch_count: ${{ steps.set-matrix.outputs.count }}

    steps:
      - name: Parse branches
        id: set-matrix
        run: |
          BRANCHES="${{ github.event.inputs.branches }}"
          # カンマ区切りを配列に変換
          IFS=',' read -ra BRANCH_ARRAY <<< "$BRANCHES"

          # スペースをトリム
          CLEANED_BRANCHES=()
          for branch in "${BRANCH_ARRAY[@]}"; do
            trimmed=$(echo "$branch" | xargs)
            CLEANED_BRANCHES+=("\"$trimmed\"")
          done

          # JSON配列を作成
          BRANCH_JSON="[${CLEANED_BRANCHES[*]}]"
          BRANCH_JSON="${BRANCH_JSON// /,}"

          echo "matrix=$BRANCH_JSON" >> $GITHUB_OUTPUT
          echo "count=${#BRANCH_ARRAY[@]}" >> $GITHUB_OUTPUT

          echo "🌳 Testing ${#BRANCH_ARRAY[@]} branches:"
          for branch in "${BRANCH_ARRAY[@]}"; do
            echo "  - $(echo $branch | xargs)"
          done

  # 各ブランチを並行実行
  test-branch:
    name: Test ${{ matrix.branch }}
    runs-on: ubuntu-latest
    needs: prepare
    strategy:
      fail-fast: false
      matrix:
        branch: ${{ fromJson(needs.prepare.outputs.matrix) }}
        node: [20]

    steps:
      - name: Checkout branch ${{ matrix.branch }}
        uses: actions/checkout@v4
        with:
          ref: ${{ matrix.branch }}
          fetch-depth: 0

      - name: Setup Node.js ${{ matrix.node }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node }}
          cache: 'npm'

      - name: Get branch info
        id: branch_info
        run: |
          BRANCH_NAME="${{ matrix.branch }}"
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%s)
          BRANCH_SAFE=$(echo "$BRANCH_NAME" | sed 's/[^a-zA-Z0-9]/-/g')

          echo "branch_safe=$BRANCH_SAFE" >> $GITHUB_OUTPUT
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg=$COMMIT_MSG" >> $GITHUB_OUTPUT

          echo "📋 Branch: $BRANCH_NAME"
          echo "📝 Commit: $COMMIT_SHA - $COMMIT_MSG"

      - name: Install dependencies
        run: |
          echo "📦 Installing dependencies for ${{ matrix.branch }}..."
          npm ci

      - name: Run linting
        id: lint
        run: |
          echo "🔍 Running linting..."
          npm run lint > lint-output.txt 2>&1 || true
          cat lint-output.txt

          if grep -q "error" lint-output.txt; then
            echo "status=failed" >> $GITHUB_OUTPUT
          else
            echo "status=passed" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Run build
        id: build
        if: github.event.inputs.run_build == 'true'
        run: |
          echo "🔨 Building ${{ matrix.branch }}..."
          START_TIME=$(date +%s)

          npm run build > build-output.txt 2>&1 || BUILD_FAILED=1

          END_TIME=$(date +%s)
          BUILD_TIME=$((END_TIME - START_TIME))

          echo "duration=$BUILD_TIME" >> $GITHUB_OUTPUT

          if [ "$BUILD_FAILED" == "1" ]; then
            echo "status=failed" >> $GITHUB_OUTPUT
            cat build-output.txt
            exit 1
          else
            echo "status=passed" >> $GITHUB_OUTPUT
            echo "✅ Build completed in ${BUILD_TIME}s"
          fi
        continue-on-error: true

      - name: Run tests
        id: test
        if: github.event.inputs.run_tests == 'true'
        run: |
          echo "🧪 Running tests for ${{ matrix.branch }}..."
          START_TIME=$(date +%s)

          npm test > test-output.txt 2>&1 || TEST_FAILED=1

          END_TIME=$(date +%s)
          TEST_TIME=$((END_TIME - START_TIME))

          echo "duration=$TEST_TIME" >> $GITHUB_OUTPUT

          if [ "$TEST_FAILED" == "1" ]; then
            echo "status=failed" >> $GITHUB_OUTPUT
            cat test-output.txt
          else
            echo "status=passed" >> $GITHUB_OUTPUT
            echo "✅ Tests completed in ${TEST_TIME}s"
          fi

          # テスト結果をカウント
          PASS_COUNT=$(grep -c "# pass" test-output.txt || echo "0")
          FAIL_COUNT=$(grep -c "# fail" test-output.txt || echo "0")

          echo "pass_count=$PASS_COUNT" >> $GITHUB_OUTPUT
          echo "fail_count=$FAIL_COUNT" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Generate branch report
        run: |
          REPORT_DIR="reports/${{ steps.branch_info.outputs.branch_safe }}"
          mkdir -p "$REPORT_DIR"

          cat > "$REPORT_DIR/summary.json" << EOF
          {
            "branch": "${{ matrix.branch }}",
            "commit": "${{ steps.branch_info.outputs.commit_sha }}",
            "commit_message": "${{ steps.branch_info.outputs.commit_msg }}",
            "node_version": "${{ matrix.node }}",
            "lint_status": "${{ steps.lint.outputs.status }}",
            "build_status": "${{ steps.build.outputs.status }}",
            "build_duration": "${{ steps.build.outputs.duration }}",
            "test_status": "${{ steps.test.outputs.status }}",
            "test_duration": "${{ steps.test.outputs.duration }}",
            "test_pass": "${{ steps.test.outputs.pass_count }}",
            "test_fail": "${{ steps.test.outputs.fail_count }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          }
          EOF

          # Markdown レポート生成
          cat > "$REPORT_DIR/report.md" << EOF
          # Test Report: ${{ matrix.branch }}

          ## Branch Information
          - **Branch**: \`${{ matrix.branch }}\`
          - **Commit**: \`${{ steps.branch_info.outputs.commit_sha }}\`
          - **Message**: ${{ steps.branch_info.outputs.commit_msg }}
          - **Node.js**: ${{ matrix.node }}

          ## Results

          | Check | Status | Duration |
          |-------|--------|----------|
          | Lint | ${{ steps.lint.outputs.status == 'passed' && '✅ Passed' || '❌ Failed' }} | - |
          | Build | ${{ steps.build.outputs.status == 'passed' && '✅ Passed' || steps.build.outputs.status == 'failed' && '❌ Failed' || '⏭️ Skipped' }} | ${{ steps.build.outputs.duration }}s |
          | Tests | ${{ steps.test.outputs.status == 'passed' && '✅ Passed' || steps.test.outputs.status == 'failed' && '❌ Failed' || '⏭️ Skipped' }} | ${{ steps.test.outputs.duration }}s |

          ### Test Details
          - **Passed**: ${{ steps.test.outputs.pass_count }}
          - **Failed**: ${{ steps.test.outputs.fail_count }}
          EOF

          cat "$REPORT_DIR/report.md"

      - name: Upload branch artifacts
        uses: actions/upload-artifact@v4
        with:
          name: report-${{ steps.branch_info.outputs.branch_safe }}
          path: reports/
          retention-days: 30

  # 全ブランチの結果を比較
  compare:
    name: Compare results
    runs-on: ubuntu-latest
    needs: [prepare, test-branch]
    if: github.event.inputs.compare_results == 'true'
    permissions:
      contents: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all reports
        uses: actions/download-artifact@v4
        with:
          path: all-reports

      - name: Generate comparison report
        run: |
          mkdir -p comparison

          cat > comparison/README.md << 'EOF'
          # Worktree Parallel Testing - Comparison Report

          ## Overview
          This report compares the results of parallel testing across multiple branches.

          ## Tested Branches
          EOF

          echo "Testing ${{ needs.prepare.outputs.branch_count }} branches" >> comparison/README.md
          echo "" >> comparison/README.md

          # 各ブランチのレポートを統合
          cat >> comparison/README.md << 'EOF'
          ## Comparison Table

          | Branch | Commit | Lint | Build | Build Time | Tests | Test Time | Pass | Fail |
          |--------|--------|------|-------|------------|-------|-----------|------|------|
          EOF

          for report_dir in all-reports/report-*/; do
            if [ -f "$report_dir/*/summary.json" ]; then
              JSON_FILE=$(find "$report_dir" -name "summary.json" | head -1)

              BRANCH=$(jq -r '.branch' "$JSON_FILE")
              COMMIT=$(jq -r '.commit' "$JSON_FILE")
              LINT=$(jq -r '.lint_status' "$JSON_FILE")
              BUILD=$(jq -r '.build_status' "$JSON_FILE")
              BUILD_DUR=$(jq -r '.build_duration' "$JSON_FILE")
              TEST=$(jq -r '.test_status' "$JSON_FILE")
              TEST_DUR=$(jq -r '.test_duration' "$JSON_FILE")
              PASS=$(jq -r '.test_pass' "$JSON_FILE")
              FAIL=$(jq -r '.test_fail' "$JSON_FILE")

              LINT_ICON=$([[ "$LINT" == "passed" ]] && echo "✅" || echo "❌")
              BUILD_ICON=$([[ "$BUILD" == "passed" ]] && echo "✅" || [[ "$BUILD" == "failed" ]] && echo "❌" || echo "⏭️")
              TEST_ICON=$([[ "$TEST" == "passed" ]] && echo "✅" || [[ "$TEST" == "failed" ]] && echo "❌" || echo "⏭️")

              echo "| $BRANCH | \`$COMMIT\` | $LINT_ICON | $BUILD_ICON | ${BUILD_DUR}s | $TEST_ICON | ${TEST_DUR}s | $PASS | $FAIL |" >> comparison/README.md
            fi
          done

          cat >> comparison/README.md << 'EOF'

          ## Recommendations

          Based on the test results:
          1. ✅ Branches with all tests passing are ready for merge
          2. ⚠️  Branches with build failures need attention
          3. ❌ Branches with test failures require fixes

          ## Next Steps
          1. Review failed branches
          2. Fix any issues
          3. Choose the best implementation
          4. Merge to main branch
          EOF

          cat comparison/README.md

      - name: 🤖 AI Code Comparison with Claude
        uses: anthropics/claude-code-action@beta
        with:
          mode: agent
          direct_prompt: |
            # 複数ブランチの実装比較評価タスク

            あなたは経験豊富なシニアエンジニアです。複数の実装を深く分析し、最良の選択を提案してください。

            ## 📋 タスク概要

            `all-reports/` ディレクトリに複数のブランチのテスト結果が保存されています。
            **必ず全ブランチの実装コードを読み込んで**、詳細な比較評価を行ってください。

            ## 🔍 実施内容

            ### Phase 1: ブランチとコードの把握

            1. `all-reports/` 内の各レポートから `summary.json` を読み込む
            2. **各ブランチのメインコードを必ず読み込む**
               - `git show <branch>:<file-path>` または checkout して読む
               - 主要な変更ファイルを特定して全て確認
               - 実装の全体像を把握する

            ### Phase 2: 評価軸の決定

            **コードを読んだ上で**、このプロジェクトに最適な評価軸を自分で考えてください。

            例（参考）：
            - パフォーマンス（実行速度、メモリ使用量）
            - コード品質（可読性、保守性、設計パターン）
            - テスト品質（カバレッジ、テストの質）
            - セキュリティ（脆弱性、安全性）
            - 拡張性（将来の機能追加のしやすさ）
            - 技術的負債（リファクタリングの必要性）

            **プロジェクトの特性に応じて、独自の評価軸を追加してください。**

            ### Phase 3: 詳細評価

            各ブランチについて、Phase 2 で決定した評価軸で詳細に分析してください。
            **必ずコードの具体的な箇所を引用**して根拠を示してください。

            ### Phase 4: HTML レポート生成

            `comparison/ai-analysis.html` ファイルを作成してください。

            **必須構成**：

            ```html
            <!DOCTYPE html>
            <html lang="ja">
            <head>
              <meta charset="UTF-8">
              <meta name="viewport" content="width=device-width, initial-scale=1.0">
              <title>AI Code Comparison Report</title>
              <style>
                body { font-family: system-ui, -apple-system, sans-serif; max-width: 1200px; margin: 0 auto; padding: 20px; line-height: 1.6; }
                h1 { color: #2563eb; border-bottom: 3px solid #2563eb; padding-bottom: 10px; }
                h2 { color: #1e40af; margin-top: 40px; }
                .executive-summary { background: #eff6ff; padding: 20px; border-left: 4px solid #2563eb; margin: 20px 0; }
                .ranking { display: flex; flex-direction: column; gap: 20px; margin: 20px 0; }
                .rank-item { background: #f9fafb; border: 1px solid #e5e7eb; border-radius: 8px; padding: 20px; }
                .rank-1 { border-left: 6px solid #10b981; background: #f0fdf4; }
                .rank-2 { border-left: 6px solid #3b82f6; background: #eff6ff; }
                .rank-3 { border-left: 6px solid #f59e0b; background: #fffbeb; }
                .code-ref { background: #1e293b; color: #e2e8f0; padding: 2px 6px; border-radius: 4px; font-family: monospace; font-size: 0.9em; }
                table { width: 100%; border-collapse: collapse; margin: 20px 0; }
                th, td { border: 1px solid #e5e7eb; padding: 12px; text-align: left; }
                th { background: #f3f4f6; font-weight: 600; }
                .metric-good { color: #10b981; font-weight: 600; }
                .metric-warn { color: #f59e0b; font-weight: 600; }
                .metric-bad { color: #ef4444; font-weight: 600; }
              </style>
            </head>
            <body>
              <h1>🤖 AI Code Comparison Report</h1>

              <!-- 1. Executive Summary（必須） -->
              <div class="executive-summary">
                <h2>📊 Executive Summary</h2>
                <p><strong>評価対象</strong>: [ブランチ数] 個のブランチ</p>
                <p><strong>推奨ブランチ</strong>: [最も優れたブランチ名]</p>
                <p><strong>推奨理由（要約）</strong>: [1-2文で簡潔に]</p>
                <p><strong>主な発見</strong>: [重要なポイントを3-5個箇条書き]</p>
              </div>

              <!-- 2. ランキング（必須） -->
              <h2>🏆 総合ランキング</h2>
              <div class="ranking">
                <div class="rank-item rank-1">
                  <h3>🥇 1位: [ブランチ名]</h3>
                  <p><strong>総合評価</strong>: ⭐⭐⭐⭐⭐ (5/5)</p>
                  <p><strong>選定理由</strong>: ...</p>
                  <p><strong>強み</strong>: ...</p>
                  <p><strong>弱み</strong>: ...</p>
                </div>
                <!-- 2位、3位... -->
              </div>

              <!-- 3. 評価軸の説明 -->
              <h2>📏 評価軸</h2>
              <p>このプロジェクトの特性を考慮し、以下の評価軸を設定しました：</p>
              <table>
                <tr><th>評価軸</th><th>重要度</th><th>説明</th></tr>
                <!-- AI が決定した評価軸をここに記載 -->
              </table>

              <!-- 4. 詳細分析（各ブランチごと） -->
              <h2>🔍 詳細分析</h2>

              <h3>[ブランチ1]</h3>
              <table>
                <tr><th>評価項目</th><th>スコア</th><th>詳細</th></tr>
                <tr>
                  <td>パフォーマンス</td>
                  <td class="metric-good">90/100</td>
                  <td>ビルド時間: 15s（最速）<br>具体的なコード: <code class="code-ref">src/main.js:45-67</code> で最適化されている</td>
                </tr>
                <!-- 他の評価項目 -->
              </table>
              <p><strong>コードハイライト</strong>:</p>
              <pre><code>// src/main.js:45-67
              [実際のコードを引用]
              </code></pre>

              <!-- 5. プロジェクト固有の分析 -->
              <h2>🎯 [プロジェクト固有のセクション]</h2>
              <p>このプロジェクトの特性を考慮した追加分析...</p>

              <!-- 6. 推奨事項 -->
              <h2>💡 推奨事項</h2>
              <ol>
                <li><strong>今すぐ実施</strong>: [最優先のアクション]</li>
                <li><strong>次のステップ</strong>: [次に実施すべきこと]</li>
                <li><strong>長期的改善</strong>: [将来的な改善案]</li>
              </ol>

              <!-- 7. 結論 -->
              <h2>🎯 結論</h2>
              <p>総合的に判断して、<strong>[ブランチ名]</strong> を main にマージすることを推奨します。</p>
              <p><strong>根拠</strong>: [詳細な理由を記載]</p>
            </body>
            </html>
            ```

            ## ⚠️ 重要な指示

            1. **コードは必ず読む**: 「可能なら」ではなく、必須です
            2. **評価軸は自分で考える**: プロジェクトに最適な軸を設定
            3. **具体的なコード引用**: 評価の根拠を示す
            4. **HTML 形式**: Markdown ではなく HTML で生成
            5. **構成厳守**: Executive Summary → ランキング → 詳細
            6. **プロジェクト固有**: 画一的ではなく、このプロジェクトに合った分析
          claude_code_oauth_token: ${{ secrets.CLAUDE_ACCESS_TOKEN }}

      - name: Upload comparison report
        uses: actions/upload-artifact@v4
        with:
          name: comparison-report
          path: comparison/
          retention-days: 90

      - name: Comment on workflow
        run: |
          echo "📊 Comparison report generated successfully"
          echo "🤖 AI analysis included"
          echo "Download artifacts to view detailed results"
