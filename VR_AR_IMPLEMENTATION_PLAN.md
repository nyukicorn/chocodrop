# ChocoDrop VR/AR機能実装計画

## 📊 現状分析

### 実装済み機能
- ✅ Three.jsベースの3D空間管理
- ✅ オブジェクト配置（画像/動画）
- ✅ マウスドラッグによる移動
- ✅ キーボードによる回転・スケール変更
- ✅ エフェクト適用システム
- ✅ 削除機能（単体/全体）
- ✅ CommandUI（テキストベース操作）

### 未実装機能
- ❌ WebXR対応（VR/ARモード）
- ❌ ハンドトラッキング
- ❌ コントローラー入力
- ❌ 空間UI（3Dメニュー）
- ❌ ジェスチャー認識
- ❌ マルチユーザーコロケーション

---

## 🎯 2025年最新トレンド

### 1. WebXR Hands API
- **機能**: 25箇所の手のジョイントトラッキング
- **対応デバイス**: Meta Quest 3/3S、Vision Pro（将来）
- **用途**: コントローラーレスでのジェスチャー操作

### 2. Apple Vision Pro対応
- **visionOS 26**: `<model>`要素でUSDZファイル表示
- **M5チップ**: 高速AIワークロード（2倍速）
- **空間ウィジェット**: シームレスに統合される空間UI

### 3. Meta Quest 3新機能
- **ボディトラッキングAPI**: ジャンプ・座る動作のトラッキング
- **コロケーション機能**: 複数ユーザーの物理空間位置合わせ
- **4K相当MR体験**: 2025年夏のUIアップデート

### 4. WebXR開発ベストプラクティス
- **空間参照システム**: `XRReferenceSpace`の明示的リクエスト
- **精度向上**: `getOffsetReferenceSpace()`による数値誤差回避
- **Three.js統合**: `@react-three/xr`などのライブラリ

---

## 🚀 差別化ポイント

### A. ハイブリッドインタラクション
**既存システムとの融合**
- マウス/キーボード操作 ← **既存**
- ハンドトラッキング ← **新規**
- コントローラー ← **新規**
- **差別化**: デバイスを選ばない操作性

### B. AI × 空間コンピューティング
**ChocoDropの強み**
- AI生成コンテンツを空間配置
- ジェスチャーでAI生成を指示
- 空間内でリアルタイム編集
- **差別化**: テキストコマンド + ジェスチャーのマルチモーダル操作

### C. 直感的空間編集
**既存の編集機能をVR/AR化**
- ピンチ操作でスケール変更
- 手の回転でオブジェクト回転
- 手をかざして削除（ジェスチャー認識）
- **差別化**: 物理的な操作感覚

### D. パフォーマンス最適化
**軽量WebXR実装**
- プログレッシブ・エンハンスメント（段階的拡張）
- デバイス検出による自動最適化
- オプトインのVR/ARモード
- **差別化**: デスクトップユーザーにも影響なし

---

## 🎨 実装項目（優先度順）

### Phase 1: WebXR基盤構築（必須）

#### 1.1 WebXR Session管理
- **ファイル**: `src/client/WebXRManager.js`（新規）
- **機能**:
  - `navigator.xr`のサポート検出
  - VRセッション開始/終了
  - ARセッション開始/終了
  - フォールバック処理
- **優先度**: 🔴 最高
- **工数**: 3日

#### 1.2 Three.js VRButton/ARButton統合
- **ファイル**: `src/client/SceneManager.js`（編集）
- **機能**:
  - `THREE.VRButton.createButton(renderer)`
  - `renderer.xr.enabled = true`
  - XRアニメーションループ切り替え
- **優先度**: 🔴 最高
- **工数**: 2日

#### 1.3 空間参照システム
- **ファイル**: `src/client/WebXRManager.js`
- **機能**:
  - `viewer`参照空間（視点基準）
  - `local`参照空間（床基準）
  - `local-floor`参照空間（床高さ自動調整）
  - `bounded-floor`（プレイエリア境界）
- **優先度**: 🔴 最高
- **工数**: 2日

---

### Phase 2: ハンドトラッキング（差別化の核）

#### 2.1 WebXR Hands API実装
- **ファイル**: `src/client/HandTrackingManager.js`（新規）
- **機能**:
  - 25ジョイント位置取得
  - 手のビジュアル表示（ワイヤーフレーム/メッシュ）
  - 左右の手の状態管理
- **優先度**: 🟠 高
- **工数**: 4日

#### 2.2 ジェスチャー認識システム
- **ファイル**: `src/client/GestureRecognizer.js`（新規）
- **機能**:
  - **ピンチ検出**: 親指+人差し指
  - **グラブ検出**: 全指を握る
  - **ポイント検出**: 人差し指のみ伸ばす
  - **カスタムジェスチャー**: ポーズ登録機能
- **優先度**: 🟠 高
- **工数**: 5日

#### 2.3 ハンドインタラクション
- **ファイル**: `src/client/SceneManager.js`（編集）
- **機能**:
  - **ピンチ → つかむ**: オブジェクト選択
  - **ピンチ+移動 → ドラッグ**: オブジェクト移動
  - **両手ピンチ → スケール**: 両手の距離でスケール変更
  - **グラブ → 削除**: オブジェクトを握って消す
- **優先度**: 🟠 高
- **工数**: 6日

---

### Phase 3: コントローラー対応（汎用性）

#### 3.1 XRController統合
- **ファイル**: `src/client/ControllerManager.js`（新規）
- **機能**:
  - Quest 3コントローラー
  - Vision Proハンドコントローラー
  - Pico 4コントローラー
  - 汎用6DoFコントローラー
- **優先度**: 🟡 中
- **工数**: 4日

#### 3.2 レイキャスティング（ポインター）
- **ファイル**: `src/client/ControllerManager.js`
- **機能**:
  - コントローラーからのレイ照射
  - オブジェクト選択（トリガー）
  - ビジュアルレイライン表示
  - ホバーエフェクト
- **優先度**: 🟡 中
- **工数**: 3日

#### 3.3 コントローラーUI
- **ファイル**: `src/client/SpatialUI.js`（新規）
- **機能**:
  - コントローラー操作説明オーバーレイ
  - ボタンマッピング表示
  - 振動フィードバック
- **優先度**: 🟡 中
- **工数**: 2日

---

### Phase 4: 空間UI（使いやすさ）

#### 4.1 3Dメニューシステム
- **ファイル**: `src/client/SpatialUI.js`
- **機能**:
  - **放射状メニュー**: 手のひらに表示
  - **フローティングパネル**: WorldSpace UI
  - **コンテキストメニュー**: オブジェクト長押し
  - **パイメニュー**: 円形ジェスチャー選択
- **優先度**: 🟡 中
- **工数**: 5日

#### 4.2 空間テキスト入力
- **ファイル**: `src/client/SpatialKeyboard.js`（新規）
- **機能**:
  - 仮想キーボード表示
  - レイポインターでタイピング
  - 音声入力（Web Speech API）
  - 既存CommandUIとの統合
- **優先度**: 🟡 中
- **工数**: 4日

#### 4.3 ビルボード情報パネル
- **ファイル**: `src/client/SceneManager.js`（編集）
- **機能**:
  - オブジェクトメタデータ表示
  - 常にカメラを向く
  - プロンプト/生成時刻/キーワード表示
  - ホバーで自動表示
- **優先度**: 🟢 低
- **工数**: 2日

---

### Phase 5: 高度な機能（突き抜け要素）

#### 5.1 マルチモーダル操作
- **ファイル**: `src/client/MultimodalController.js`（新規）
- **機能**:
  - **ジェスチャー + 音声**: "赤くして" + ポイント
  - **ジェスチャー + テキスト**: メニューから選択後ジェスチャー
  - **コントローラー + ハンド**: 片手操作
- **優先度**: 🟢 低
- **工数**: 6日

#### 5.2 空間アンカー（永続化）
- **ファイル**: `src/client/SpatialAnchorManager.js`（新規）
- **機能**:
  - AR空間にオブジェクトを固定
  - 物理座標への配置
  - セッション間の位置保存
  - QRコードマーカー連携
- **優先度**: 🟢 低
- **工数**: 5日

#### 5.3 コロケーション（共有空間）
- **ファイル**: `src/client/ColocationManager.js`（新規）
- **機能**:
  - 複数ユーザーの位置同期
  - 共有オブジェクト配置
  - リアルタイム編集共有
  - WebSocketサーバー統合
- **優先度**: 🟢 低
- **工数**: 8日

#### 5.4 ボディトラッキング
- **ファイル**: `src/client/BodyTrackingManager.js`（新規）
- **機能**:
  - Quest 3ボディトラッキングAPI
  - ジャンプ・座る動作検出
  - 全身ジェスチャー認識
  - アバター連動
- **優先度**: 🟢 低
- **工数**: 7日

---

## 🛠️ 技術スタック

### 既存
- Three.js (0.170.0+)
- WebGL
- Express
- SSE (Server-Sent Events)

### 追加
- **WebXR Device API**: VR/ARセッション管理
- **WebXR Hands API**: ハンドトラッキング
- **Web Speech API**: 音声入力（オプション）
- **IndexedDB**: 空間アンカー永続化
- **WebSocket**: コロケーション通信
- **Three.js拡張**:
  - `VRButton`
  - `ARButton`
  - `XRControllerModelFactory`
  - `XRHandModelFactory`

---

## 📈 実装ロードマップ

### スプリント1（2週間）: WebXR基盤
- WebXRManager実装
- VRButton/ARButton統合
- 空間参照システム
- **ゴール**: VRモードで既存機能が動作

### スプリント2（3週間）: ハンドトラッキング
- HandTrackingManager実装
- ジェスチャー認識システム
- ハンドインタラクション
- **ゴール**: 手でオブジェクトを掴んで移動できる

### スプリント3（2週間）: コントローラー
- ControllerManager実装
- レイキャスティング
- コントローラーUI
- **ゴール**: コントローラーでもハンドでも操作可能

### スプリント4（2週間）: 空間UI
- 3Dメニューシステム
- 空間テキスト入力
- ビルボード情報パネル
- **ゴール**: VR/AR空間でのコマンド入力

### スプリント5（3週間）: 高度な機能
- マルチモーダル操作
- 空間アンカー
- コロケーション
- ボディトラッキング
- **ゴール**: 差別化機能の完成

**総工数**: 約12週間（3ヶ月）

---

## 🎯 差別化の核心戦略

### 1. AIコンテンツ生成 × 空間配置
**他にない体験**:
- ジェスチャーで「ユニコーンをここに」→ その場所にAI生成画像が出現
- 両手で範囲指定 → その範囲内に複数オブジェクト配置
- 空間コマンド: 手をかざして「赤くして」→ エフェクト適用

### 2. プログレッシブ・エンハンスメント
**段階的な体験向上**:
```
デスクトップ
  ↓ (WebXR対応デバイス)
VRモード（コントローラー）
  ↓ (ハンドトラッキング対応)
VRモード（ハンド）
  ↓ (ARモード)
MR体験（空間アンカー）
  ↓ (マルチユーザー)
共有MR空間
```

### 3. ゼロラーニングコスト
**既存UIを活かす**:
- デスクトップユーザー: 変化なし
- VRユーザー: チュートリアル自動表示
- 操作方法の自動検出（デバイス対応に応じて）

### 4. パフォーマンス優先
**軽量実装**:
- WebXRManager: 500行以内
- HandTrackingManager: 800行以内
- オプトイン設計（VRモードボタンを押すまで未初期化）

---

## 🔍 競合比較

| 機能 | ChocoDrop | VRChat | Mozilla Hubs | Spatial |
|------|-----------|---------|--------------|---------|
| AIコンテンツ生成 | ✅ | ❌ | ❌ | ❌ |
| ハンドトラッキング | ✅ (予定) | ✅ | ✅ | ✅ |
| 空間配置 | ✅ | ✅ | ✅ | ✅ |
| テキストコマンド | ✅ | ❌ | ❌ | ❌ |
| Web対応 | ✅ | ❌ | ✅ | ❌ |
| マルチモーダル | ✅ (予定) | ❌ | ❌ | ❌ |
| デスクトップ対応 | ✅ | ❌ | ✅ | ✅ |

**差別化ポイント**:
1. **AI生成 × 空間配置**: 業界初
2. **テキストコマンド + ジェスチャー**: マルチモーダルの先駆け
3. **プログレッシブ対応**: すべてのユーザーに最適化

---

## 📊 成功指標（KPI）

### Phase 1完了時
- [ ] WebXR対応デバイスで起動可能
- [ ] VRモードでオブジェクト配置が動作
- [ ] 既存デスクトップ機能に影響なし

### Phase 2完了時
- [ ] ハンドトラッキングでオブジェクト移動可能
- [ ] 5種類以上のジェスチャー認識
- [ ] 操作精度95%以上

### Phase 3完了時
- [ ] Quest 3コントローラー対応
- [ ] レイキャスト選択が動作
- [ ] コントローラーとハンドの切り替えがシームレス

### Phase 4完了時
- [ ] 空間UIでコマンド入力可能
- [ ] 仮想キーボードが動作
- [ ] ビルボードUIが自動表示

### Phase 5完了時
- [ ] マルチモーダル操作が動作
- [ ] 空間アンカーでAR配置可能
- [ ] 2人以上のコロケーション成功

---

## 🚧 リスクと対策

### リスク1: デバイス非対応
**問題**: WebXR非対応ブラウザでの動作
**対策**: プログレッシブ・エンハンスメント（既存機能に影響なし）

### リスク2: パフォーマンス劣化
**問題**: VRモードでのフレームレート低下
**対策**: LOD（Level of Detail）実装、オブジェクト数制限

### リスク3: ジェスチャー誤認識
**問題**: 意図しない操作が発生
**対策**: 確認ステップの追加、アンドゥ機能の強化

### リスク4: 開発工数超過
**問題**: 予定より時間がかかる
**対策**: Phase 1-3を最優先、Phase 4-5は段階的リリース

---

## 📝 まとめ

### 最優先実装（Phase 1-2）
1. **WebXR基盤構築**: 3日 + 2日 + 2日 = 7日
2. **ハンドトラッキング**: 4日 + 5日 + 6日 = 15日
**合計**: 約22日（1ヶ月）

### これにより達成できること
- ✅ VR/ARモードでChocoDrop起動
- ✅ 手でオブジェクトを掴んで移動
- ✅ ジェスチャーでスケール変更
- ✅ ピンチでAI生成コンテンツ配置
- ✅ グラブでオブジェクト削除

### 差別化の核心
**「AI生成コンテンツを、手で空間に配置し、直感的に編集できる唯一のWebXRプラットフォーム」**

この実装により、ChocoDrop は2025年の空間コンピューティング時代において、創作ツールとして突き抜けた存在になります。
